{
 "cells": [
 
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e892c632-daee-4b0a-8dd1-54452d221a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset invertido generado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "\n",
    "# === Paths ===\n",
    "base_old = \"/home/mdb/DL_Lab3/UAM_DATASET/stratified_correct/Rubish/\"\n",
    "base_new = \"/home/mdb/DL_Lab3/UAM_DATASET/stratified_correct_inv/Rubish/\"\n",
    "\n",
    "for folder in [\"image_train\", \"image_test\", \"image_query\"]:\n",
    "    os.makedirs(os.path.join(base_new, folder), exist_ok=True)\n",
    "\n",
    "# === XMLS ===\n",
    "xmls = {\n",
    "    \"train_label.xml\": \"image_train\",\n",
    "    \"test_label.xml\": \"image_test\",\n",
    "    \"query_label.xml\": \"image_query\"\n",
    "}\n",
    "\n",
    "for xml_name, img_folder in xmls.items():\n",
    "    xml_path = os.path.join(base_old, xml_name)\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    items = root.find(\"Items\").findall(\"Item\")\n",
    "\n",
    "    for item in items:\n",
    "        img_name = item.attrib[\"imageName\"]\n",
    "        camera_id = item.attrib[\"cameraID\"]\n",
    "        src_path = os.path.join(base_old, img_folder, img_name)\n",
    "        dst_path = os.path.join(base_new, img_folder, img_name)\n",
    "\n",
    "        if not os.path.exists(src_path):\n",
    "            print(f\"Imagen no encontrada: {src_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if camera_id == \"c004\":\n",
    "                # Flip horizontal\n",
    "                img = Image.open(src_path).convert(\"RGB\")\n",
    "                img.transpose(Image.FLIP_LEFT_RIGHT).save(dst_path)\n",
    "            else:\n",
    "                # Copia directa\n",
    "                shutil.copy(src_path, dst_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {src_path}: {e}\")\n",
    "\n",
    "    # Copiar también el XML sin modificar\n",
    "    shutil.copy(xml_path, os.path.join(base_new, xml_name))\n",
    "\n",
    "print(\"Dataset invertido generado correctamente.\")\n"
   ]
  },
  
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8dad1fa-d8eb-484a-a620-400985426507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/mdb/.local/spyder-6/envs/spyder-runtime/lib/python3.11/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/mdb/.local/spyder-6/envs/spyder-runtime/lib/python3.11/site-packages (from opencv-python) (2.2.2)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Configura los proxies\n",
    "os.environ[\"http_proxy\"] = \"http://192.168.22.3:8080\"\n",
    "os.environ[\"https_proxy\"] = \"http://192.168.22.3:8080\"\n",
    "\n",
    "# Instala opencv-python correctamente\n",
    "!pip install opencv-python\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45999770-e4ce-432e-a300-ce9c4af56c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando train_label.xml: 100%|██████████| 28440/28440 [01:30<00:00, 314.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset invertido + augmentado con ColorJitter y Random Patch generado correctamente.\n",
      "\n",
      "Verificando que todas las imágenes estén anotadas en el XML...\n",
      "Todas las imágenes tienen anotación.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "base_old = \"/home/mdb/DL_Lab3/ST_DATASETS/ALL_COMBINED_DATASET/Unified/\"\n",
    "base_new = \"/home/mdb/DL_Lab3/ST_DATASETS/ALL_COMBINED_DATASET_AUGM/Unified/\"\n",
    "\n",
    "for folder in [\"image_train\"]:\n",
    "    os.makedirs(os.path.join(base_new, folder), exist_ok=True)\n",
    "\n",
    "# Augmentation config\n",
    "augmentation_probs = [0.15, 0.45, 0.40]  # Probabilidades de 0, 1 o 2 augmentaciones\n",
    "\n",
    "def perspective_transform_cv2(img):\n",
    "    h, w = img.shape[:2]\n",
    "    delta = int(w * 0.15)\n",
    "    direction = random.choice([\"left\", \"right\"])\n",
    "    src = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "    if direction == \"left\":\n",
    "        dst = np.float32([[delta, 0], [w, 0], [0, h], [w - delta, h]])\n",
    "    else:\n",
    "        dst = np.float32([[0, 0], [w - delta, 0], [delta, h], [w, h]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    return cv2.warpPerspective(img, M, (w, h), borderMode=cv2.BORDER_REFLECT101)\n",
    "\n",
    "def change_lighting(img):\n",
    "    alpha = random.uniform(0.7, 1.3)  # Contraste\n",
    "    beta = random.randint(-20, 20)    # Brillo\n",
    "    return cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "\n",
    "def rotate_image(img):\n",
    "    h, w = img.shape[:2]\n",
    "    angle = random.uniform(-5, 5)  # rotación leve\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)\n",
    "    return cv2.warpAffine(img, M, (w, h), borderMode=cv2.BORDER_REFLECT101)\n",
    "\n",
    "def zoom_in_crop(img):\n",
    "    h, w = img.shape[:2]\n",
    "    zoom_factor = random.uniform(0.8, 0.95)  # crop 5–10%\n",
    "    new_w, new_h = int(w * zoom_factor), int(h * zoom_factor)\n",
    "    x1 = (w - new_w) // 2\n",
    "    y1 = (h - new_h) // 2\n",
    "    cropped = img[y1:y1+new_h, x1:x1+new_w]\n",
    "    return cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def color_jitter(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    hsv[:, :, 1] *= random.uniform(0.8, 1.2)  # Saturación\n",
    "    hsv[:, :, 2] *= random.uniform(0.8, 1.2)  # Brillo\n",
    "    hsv = np.clip(hsv, 0, 255)\n",
    "    return cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def insert_random_patch(img, all_images):\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Tamaño del parche: aleatorio entre 20% y 50% del ancho y alto\n",
    "    scale = random.uniform(0.25, 0.5)\n",
    "    patch_w = int(w * scale)\n",
    "    patch_h = int(h * scale)\n",
    "\n",
    "    # Imagen de origen aleatoria para el parche\n",
    "    src_img = random.choice(all_images)\n",
    "    if src_img.shape != img.shape:\n",
    "        src_img = cv2.resize(src_img, (w, h))\n",
    "\n",
    "    # Coordenadas del parche dentro de la imagen fuente\n",
    "    x = random.randint(0, w - patch_w)\n",
    "    y = random.randint(0, h - patch_h)\n",
    "    patch = src_img[y:y + patch_h, x:x + patch_w]\n",
    "\n",
    "    # Coordenadas de inserción en la imagen objetivo\n",
    "    px = random.randint(0, w - patch_w)\n",
    "    py = random.randint(0, h - patch_h)\n",
    "\n",
    "    img[py:py + patch_h, px:px + patch_w] = patch\n",
    "    return img\n",
    "\n",
    "\n",
    "def augment_image(img, all_images):\n",
    "    img = perspective_transform_cv2(img)\n",
    "    img = change_lighting(img)\n",
    "    img = rotate_image(img)\n",
    "    img = zoom_in_crop(img)\n",
    "    img = color_jitter(img)\n",
    "    img = insert_random_patch(img, all_images)\n",
    "    return img\n",
    "\n",
    "# Cargar imágenes originales para patching\n",
    "all_train_imgs = []\n",
    "train_dir = os.path.join(base_old, \"image_train\")\n",
    "for name in os.listdir(train_dir):\n",
    "    path = os.path.join(train_dir, name)\n",
    "    try:\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            all_train_imgs.append(img)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# XMLS\n",
    "xmls = {\n",
    "    \"train_label.xml\": \"image_train\"\n",
    "}\n",
    "\n",
    "for xml_name, img_folder in xmls.items():\n",
    "    xml_path = os.path.join(base_old, xml_name)\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    items = root.findall(\"Item\") if root.tag == \"Items\" else root.find(\"Items\").findall(\"Item\")\n",
    "\n",
    "    if xml_name == \"train_label.xml\":\n",
    "        new_tree = ET.ElementTree(ET.Element(\"TrainingImages\", Version=\"1.0\"))\n",
    "        new_items = ET.SubElement(new_tree.getroot(), \"Items\")\n",
    "        total_items = 0\n",
    "\n",
    "    for item in tqdm(items, desc=f\"Procesando {xml_name}\"):\n",
    "        img_name = item.attrib[\"imageName\"]\n",
    "        camera_id = item.attrib[\"cameraID\"]\n",
    "        object_id = item.attrib[\"objectID\"]\n",
    "        src_path = os.path.join(base_old, img_folder, img_name)\n",
    "        dst_path = os.path.join(base_new, img_folder, img_name)\n",
    "\n",
    "        if not os.path.exists(src_path):\n",
    "            print(f\"Imagen no encontrada: {src_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            pil_img = Image.open(src_path).convert(\"RGB\")\n",
    "            if camera_id == \"c004\":\n",
    "                pil_img = pil_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            pil_img.save(dst_path)\n",
    "\n",
    "            if xml_name == \"train_label.xml\":\n",
    "                ET.SubElement(new_items, \"Item\", cameraID=camera_id, imageName=img_name, objectID=object_id)\n",
    "                total_items += 1\n",
    "\n",
    "                img_cv2 = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "                num_aug = random.choices([0, 1, 2], weights=augmentation_probs, k=1)[0]\n",
    "                base_name, ext = os.path.splitext(img_name)\n",
    "\n",
    "                for i in range(num_aug):\n",
    "                    aug_img = augment_image(img_cv2.copy(), all_train_imgs)\n",
    "                    aug_img_rgb = cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB)\n",
    "                    aug_pil = Image.fromarray(aug_img_rgb)\n",
    "                    aug_name = f\"{base_name}_aug{i+1}{ext}\"\n",
    "                    aug_path = os.path.join(base_new, img_folder, aug_name)\n",
    "                    aug_pil.save(aug_path)\n",
    "                    ET.SubElement(new_items, \"Item\", cameraID=camera_id, imageName=aug_name, objectID=object_id)\n",
    "                    total_items += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {src_path}: {e}\")\n",
    "\n",
    "    if xml_name == \"train_label.xml\":\n",
    "        new_items.set(\"number\", str(total_items))\n",
    "        new_tree.write(os.path.join(base_new, xml_name))\n",
    "    else:\n",
    "        shutil.copy(xml_path, os.path.join(base_new, xml_name))\n",
    "\n",
    "print(\"Dataset invertido + augmentado con ColorJitter y Random Patch generado correctamente.\")\n",
    "print(\"\\nVerificando que todas las imágenes estén anotadas en el XML...\")\n",
    "\n",
    "# Cargar XML generado\n",
    "xml_path = os.path.join(base_new, \"train_label.xml\")\n",
    "tree = ET.parse(xml_path)\n",
    "root = tree.getroot()\n",
    "items_node = root.find(\"Items\")\n",
    "annotated_imgs = {item.attrib[\"imageName\"] for item in items_node.findall(\"Item\")}\n",
    "\n",
    "# Listar imágenes reales en carpeta\n",
    "img_dir = os.path.join(base_new, \"image_train\")\n",
    "img_files = {f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))}\n",
    "\n",
    "# Buscar imágenes no anotadas\n",
    "missing_imgs = img_files - annotated_imgs\n",
    "if not missing_imgs:\n",
    "    print(\"Todas las imágenes tienen anotación.\")\n",
    "else:\n",
    "    print(f\"⚠️ Detectadas {len(missing_imgs)} imágenes sin anotación. Añadiendo...\")\n",
    "\n",
    "    # Crear mapa baseName → (cameraID, objectID)\n",
    "    base_info_map = {}\n",
    "    for item in items_node.findall(\"Item\"):\n",
    "        name = item.attrib[\"imageName\"]\n",
    "        base = name.split(\"_aug\")[0]\n",
    "        base_info_map[base] = (item.attrib[\"cameraID\"], item.attrib[\"objectID\"])\n",
    "\n",
    "    # Añadir elementos faltantes\n",
    "    for name in missing_imgs:\n",
    "        base = name.split(\"_aug\")[0]\n",
    "        if base in base_info_map:\n",
    "            camera_id, object_id = base_info_map[base]\n",
    "            ET.SubElement(items_node, \"Item\", cameraID=camera_id, imageName=name, objectID=object_id)\n",
    "            print(f\"Añadido: {name} ← {base}\")\n",
    "        else:\n",
    "            print(f\"No se encontró información base para: {name}\")\n",
    "\n",
    "    # Actualizar número total y guardar\n",
    "    items_node.set(\"number\", str(len(items_node.findall(\"Item\"))))\n",
    "    tree.write(xml_path)\n",
    "    print(\"Anotaciones corregidas y archivo XML actualizado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad92922-9994-4f98-8e9c-1a52c948f037",
   "metadata": {},
   "source": [
    "### Eliminar de Train las imágenes de la C004 (en Rivas no está esta camara en train) - Con Flip up y Data augm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e47b986-d6fa-4230-b232-c2c20dfdf207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando train_label.xml: 100%|██████████| 400/400 [00:00<00:00, 1405.48it/s]\n",
      "Procesando test_label.xml: 100%|██████████| 89/89 [00:00<00:00, 2079.04it/s]\n",
      "Procesando query_label.xml: 100%|██████████| 20/20 [00:00<00:00, 2059.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generado con augmentaciones y sin imágenes de c004 en entrenamiento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Paths ===\n",
    "base_old = \"/home/mdb/DL_Lab3/UAM_DATASET/stratified_correct/Rubish/\"\n",
    "base_new = \"/home/mdb/DL_Lab3/UAM_DATASET/stratified_correct_inv_augm_without_c4/Rubish/\"\n",
    "\n",
    "for folder in [\"image_train\", \"image_test\", \"image_query\"]:\n",
    "    os.makedirs(os.path.join(base_new, folder), exist_ok=True)\n",
    "\n",
    "# === Augmentation config ===\n",
    "augmentation_probs = [0.15, 0.45, 0.40]\n",
    "\n",
    "def perspective_transform_cv2(img):\n",
    "    h, w = img.shape[:2]\n",
    "    delta = int(w * 0.15)\n",
    "    direction = random.choice([\"left\", \"right\"])\n",
    "    if direction == \"left\":\n",
    "        src = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "        dst = np.float32([[delta, 0], [w, 0], [0, h], [w - delta, h]])\n",
    "    else:\n",
    "        src = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "        dst = np.float32([[0, 0], [w - delta, 0], [delta, h], [w, h]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    return cv2.warpPerspective(img, M, (w, h), borderMode=cv2.BORDER_REFLECT101)\n",
    "\n",
    "def change_lighting(img):\n",
    "    alpha = random.uniform(0.7, 1.3)\n",
    "    beta = random.randint(-20, 20)\n",
    "    return cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "\n",
    "def rotate_image(img):\n",
    "    h, w = img.shape[:2]\n",
    "    angle = random.uniform(-5, 5)\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)\n",
    "    return cv2.warpAffine(img, M, (w, h), borderMode=cv2.BORDER_REFLECT101)\n",
    "\n",
    "def zoom_in_crop(img):\n",
    "    h, w = img.shape[:2]\n",
    "    zoom_factor = random.uniform(0.8, 0.95)\n",
    "    new_w, new_h = int(w * zoom_factor), int(h * zoom_factor)\n",
    "    x1 = (w - new_w) // 2\n",
    "    y1 = (h - new_h) // 2\n",
    "    cropped = img[y1:y1+new_h, x1:x1+new_w]\n",
    "    return cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def augment_image(img):\n",
    "    img = perspective_transform_cv2(img)\n",
    "    img = change_lighting(img)\n",
    "    img = rotate_image(img)\n",
    "    img = zoom_in_crop(img)\n",
    "    return img\n",
    "\n",
    "# === XMLS ===\n",
    "xmls = {\n",
    "    \"train_label.xml\": \"image_train\",\n",
    "    \"test_label.xml\": \"image_test\",\n",
    "    \"query_label.xml\": \"image_query\"\n",
    "}\n",
    "\n",
    "for xml_name, img_folder in xmls.items():\n",
    "    xml_path = os.path.join(base_old, xml_name)\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    items = root.find(\"Items\").findall(\"Item\")\n",
    "\n",
    "    if xml_name == \"train_label.xml\":\n",
    "        new_tree = ET.ElementTree(ET.Element(\"TrainingImages\", Version=\"1.0\"))\n",
    "        new_items = ET.SubElement(new_tree.getroot(), \"Items\")\n",
    "        total_items = 0\n",
    "\n",
    "    for item in tqdm(items, desc=f\"Procesando {xml_name}\"):\n",
    "        img_name = item.attrib[\"imageName\"]\n",
    "        camera_id = item.attrib[\"cameraID\"]\n",
    "        object_id = item.attrib[\"objectID\"]\n",
    "        src_path = os.path.join(base_old, img_folder, img_name)\n",
    "        dst_path = os.path.join(base_new, img_folder, img_name)\n",
    "\n",
    "        # Si estamos en train y la imagen es de c004, la omitimos\n",
    "        if xml_name == \"train_label.xml\" and camera_id == \"c004\":\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(src_path):\n",
    "            print(f\"Imagen no encontrada: {src_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Cargar imagen original y guardar\n",
    "            pil_img = Image.open(src_path).convert(\"RGB\")\n",
    "            pil_img.save(dst_path)\n",
    "\n",
    "            if xml_name == \"train_label.xml\":\n",
    "                ET.SubElement(new_items, \"Item\", cameraID=camera_id, imageName=img_name, objectID=object_id)\n",
    "                total_items += 1\n",
    "\n",
    "                img_cv2 = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "                num_aug = random.choices([0, 1, 2], weights=augmentation_probs, k=1)[0]\n",
    "                base_name, ext = os.path.splitext(img_name)\n",
    "\n",
    "                for i in range(num_aug):\n",
    "                    aug_img = augment_image(img_cv2)\n",
    "                    aug_img_rgb = cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB)\n",
    "                    aug_pil = Image.fromarray(aug_img_rgb)\n",
    "                    aug_name = f\"{base_name}_aug{i+1}{ext}\"\n",
    "                    aug_path = os.path.join(base_new, img_folder, aug_name)\n",
    "                    aug_pil.save(aug_path)\n",
    "\n",
    "                    ET.SubElement(new_items, \"Item\", cameraID=camera_id, imageName=aug_name, objectID=object_id)\n",
    "                    total_items += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error procesando {src_path}: {e}\")\n",
    "\n",
    "    if xml_name == \"train_label.xml\":\n",
    "        new_items.set(\"number\", str(total_items))\n",
    "        new_tree.write(os.path.join(base_new, xml_name))\n",
    "    else:\n",
    "        shutil.copy(xml_path, os.path.join(base_new, xml_name))\n",
    "\n",
    "print(\"Dataset generado con augmentaciones y sin imágenes de c004 en entrenamiento.\")\n"
   ]
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
