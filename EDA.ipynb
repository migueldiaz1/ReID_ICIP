{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05559326-8557-4425-8099-cfa3a8af01ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== INICIANDO EDA COMPLETO =====\n",
      "\n",
      "===== Dataset: UAM =====\n",
      "\n",
      "--- Clase: Containers ---\n",
      "image_train: 1697 imágenes\n",
      "  Tamaño medio: [129.82144962 103.90218032]\n",
      "  Tamaño mínimo: [12 13]\n",
      "  Tamaño máximo: [816 549]\n",
      "image_test: 272 imágenes\n",
      "  Tamaño medio: [125.01838235 103.97426471]\n",
      "  Tamaño mínimo: [18 17]\n",
      "  Tamaño máximo: [ 616 1131]\n",
      "image_query: 98 imágenes\n",
      "  Tamaño medio: [63.84693878 56.47959184]\n",
      "  Tamaño mínimo: [17 12]\n",
      "  Tamaño máximo: [371 343]\n",
      "train_label.xml: 83 IDs únicos, 1585 imágenes\n",
      "test_label.xml: 0 IDs únicos, 0 imágenes\n",
      "query_label.xml: 0 IDs únicos, 0 imágenes\n",
      "\n",
      "--- Clase: Crosswalks ---\n",
      "image_train: 1352 imágenes\n",
      "  Tamaño medio: [118.03328402 598.69748521]\n",
      "  Tamaño mínimo: [16 23]\n",
      "  Tamaño máximo: [ 527 1920]\n",
      "image_test: 350 imágenes\n",
      "  Tamaño medio: [123.26285714 691.82      ]\n",
      "  Tamaño mínimo: [13 42]\n",
      "  Tamaño máximo: [ 520 1920]\n",
      "image_query: 90 imágenes\n",
      "  Tamaño medio: [156.28888889 738.62222222]\n",
      "  Tamaño mínimo: [17 87]\n",
      "  Tamaño máximo: [ 523 1920]\n",
      "train_label.xml: 102 IDs únicos, 1331 imágenes\n",
      "test_label.xml: 0 IDs únicos, 0 imágenes\n",
      "query_label.xml: 0 IDs únicos, 0 imágenes\n",
      "\n",
      "--- Clase: Rubish ---\n",
      "image_train: 417 imágenes\n",
      "  Tamaño medio: [65.18465228 45.63788969]\n",
      "  Tamaño mínimo: [18 14]\n",
      "  Tamaño máximo: [275 169]\n",
      "image_test: 92 imágenes\n",
      "  Tamaño medio: [67.13043478 46.82608696]\n",
      "  Tamaño mínimo: [17 17]\n",
      "  Tamaño máximo: [212 165]\n",
      "image_query: 29 imágenes\n",
      "  Tamaño medio: [55.93103448 38.13793103]\n",
      "  Tamaño mínimo: [17 12]\n",
      "  Tamaño máximo: [184 100]\n",
      "train_label.xml: 46 IDs únicos, 391 imágenes\n",
      "test_label.xml: 0 IDs únicos, 0 imágenes\n",
      "query_label.xml: 0 IDs únicos, 0 imágenes\n",
      "\n",
      "===== Dataset: RIVAS =====\n",
      "\n",
      "--- Clase: Containers ---\n",
      "image_train: 1189 imágenes\n",
      "  Tamaño medio: [143.16063919 114.27586207]\n",
      "  Tamaño mínimo: [24 15]\n",
      "  Tamaño máximo: [781 548]\n",
      "image_test: 261 imágenes\n",
      "  Tamaño medio: [158.55938697 122.05363985]\n",
      "  Tamaño mínimo: [29 16]\n",
      "  Tamaño máximo: [763 556]\n",
      "image_query: 167 imágenes\n",
      "  Tamaño medio: [139.10778443 106.32934132]\n",
      "  Tamaño mínimo: [21 14]\n",
      "  Tamaño máximo: [827 512]\n",
      "train_label.xml: 87 IDs únicos, 1189 imágenes\n",
      "test_label.xml: 0 IDs únicos, 0 imágenes\n",
      "query_label.xml: 0 IDs únicos, 0 imágenes\n",
      "\n",
      "--- Clase: Crosswalks ---\n",
      "image_train: 1532 imágenes\n",
      "  Tamaño medio: [101.97062663 636.154047  ]\n",
      "  Tamaño mínimo: [ 6 56]\n",
      "  Tamaño máximo: [ 511 1920]\n",
      "image_test: 354 imágenes\n",
      "  Tamaño medio: [ 94.5819209  571.12429379]\n",
      "  Tamaño mínimo: [ 8 81]\n",
      "  Tamaño máximo: [ 439 1920]\n",
      "image_query: 91 imágenes\n",
      "  Tamaño medio: [131.2967033  717.37362637]\n",
      "  Tamaño mínimo: [ 11 118]\n",
      "  Tamaño máximo: [ 484 1920]\n",
      "train_label.xml: 111 IDs únicos, 1532 imágenes\n",
      "test_label.xml: 0 IDs únicos, 0 imágenes\n",
      "query_label.xml: 0 IDs únicos, 0 imágenes\n",
      "\n",
      "--- Clase: Rubish ---\n",
      "image_train: 886 imágenes\n",
      "  Tamaño medio: [77.86568849 47.53950339]\n",
      "  Tamaño mínimo: [18 12]\n",
      "  Tamaño máximo: [333 227]\n",
      "image_test: 393 imágenes\n",
      "  Tamaño medio: [96.77862595 58.07124682]\n",
      "  Tamaño mínimo: [15  7]\n",
      "  Tamaño máximo: [353 207]\n",
      "image_query: 88 imágenes\n",
      "  Tamaño medio: [90.32954545 49.44318182]\n",
      "  Tamaño mínimo: [24 14]\n",
      "  Tamaño máximo: [307 166]\n",
      "train_label.xml: 115 IDs únicos, 886 imágenes\n",
      "test_label.xml: 0 IDs únicos, 0 imágenes\n",
      "query_label.xml: 0 IDs únicos, 0 imágenes\n",
      "\n",
      "\n",
      "=== EDA COMPLETADO === 🚀\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Dataset base paths\n",
    "DATASET_PAIRS = {\n",
    "    \"UAM\": \"/home/mdb/DL_Lab3/UAM_DATASET/stratified/{}/\",\n",
    "    \"RIVAS\": \"/home/mdb/DL_Lab3/RIVAS_DATASET/DATASET/{}/\",\n",
    "}\n",
    "\n",
    "CLASSES = [\"Containers\", \"Crosswalks\", \"Rubish\"]\n",
    "SPLITS = [\"image_train\", \"image_test\", \"image_query\"]\n",
    "\n",
    "print(\"\\n===== INICIANDO EDA COMPLETO =====\\n\")\n",
    "\n",
    "for dataset_name, base_path in DATASET_PAIRS.items():\n",
    "    print(f\"===== Dataset: {dataset_name} =====\\n\")\n",
    "    \n",
    "    for class_name in CLASSES:\n",
    "        class_path = Path(base_path.format(class_name))\n",
    "        print(f\"--- Clase: {class_name} ---\")\n",
    "        \n",
    "        for split in SPLITS:\n",
    "            split_path = class_path / split\n",
    "            if not split_path.exists():\n",
    "                print(f\"  {split}: No existe\")\n",
    "                continue\n",
    "            \n",
    "            image_sizes = []\n",
    "            for img_file in os.listdir(split_path):\n",
    "                if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    img_path = split_path / img_file\n",
    "                    try:\n",
    "                        with Image.open(img_path) as img:\n",
    "                            image_sizes.append(img.size[::-1])  # (h, w)\n",
    "                    except Exception as e:\n",
    "                        print(f\"[WARNING] Error leyendo imagen {img_file}: {e}\")\n",
    "\n",
    "            image_sizes = np.array(image_sizes)\n",
    "            if len(image_sizes) > 0:\n",
    "                mean_size = np.mean(image_sizes, axis=0)\n",
    "                min_size = np.min(image_sizes, axis=0)\n",
    "                max_size = np.max(image_sizes, axis=0)\n",
    "                print(f\"{split}: {len(image_sizes)} imágenes\")\n",
    "                print(f\"  Tamaño medio: {mean_size}\")\n",
    "                print(f\"  Tamaño mínimo: {min_size}\")\n",
    "                print(f\"  Tamaño máximo: {max_size}\")\n",
    "            else:\n",
    "                print(f\"{split}: 0 imágenes\")\n",
    "        \n",
    "        # Leer XMLs de etiquetas\n",
    "        for xml_name in [\"train_label.xml\", \"test_label.xml\", \"query_label.xml\"]:\n",
    "            xml_path = class_path / xml_name\n",
    "            if not xml_path.exists():\n",
    "                print(f\"{xml_name}: No existe\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                tree = ET.parse(xml_path)\n",
    "                root = tree.getroot()\n",
    "                if root.tag == \"TrainingImages\":\n",
    "                    items = root.find(\"Items\").findall(\"Item\")\n",
    "                else:\n",
    "                    items = root.findall(\"Item\")\n",
    "                ids = [item.attrib.get(\"objectID\", None) for item in items if \"objectID\" in item.attrib]\n",
    "                unique_ids = len(set(ids))\n",
    "                total_items = len(ids)\n",
    "                print(f\"{xml_name}: {unique_ids} IDs únicos, {total_items} imágenes\")\n",
    "            except Exception as e:\n",
    "                print(f\"[WARNING] Error leyendo {xml_name}: {e}\")\n",
    "        print()\n",
    "\n",
    "print(\"\\n=== EDA COMPLETADO === 🚀\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
